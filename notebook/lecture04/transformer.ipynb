{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "研讨课内容：\n",
    "\n",
    "1 transformer 结构讲解\n",
    "\n",
    "2 transformer 改写成多标签分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# 理解语言的 Transformer 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/text/transformer\">\n",
    "    <img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" />\n",
    "    在 tensorflow.google.cn 上查看</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\" />\n",
    "    在 Google Colab 运行</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\" />\n",
    "    在 Github 上查看源代码</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/text/transformer.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\" />下载此 notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Saq5g1mnE5Y"
   },
   "source": [
    "Note: 我们的 TensorFlow 社区翻译了这些文档。因为社区翻译是尽力而为， 所以无法保证它们是最准确的，并且反映了最新的\n",
    "[官方英文文档](https://www.tensorflow.org/?hl=en)。如果您有改进此翻译的建议， 请提交 pull request 到\n",
    "[tensorflow/docs](https://github.com/tensorflow/docs) GitHub 仓库。要志愿地撰写或者审核译文，请加入\n",
    "[docs-zh-cn@tensorflow.org Google Group](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-zh-cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-f8TnGpE_ex"
   },
   "source": [
    "本教程训练了一个 <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer 模型</a> 用于将葡萄牙语翻译成英语。这是一个高级示例，假定您具备[文本生成（text generation）](text_generation.ipynb)和 [注意力机制（attention）](nmt_with_attention.ipynb) 的知识。\n",
    "\n",
    "Transformer 模型的核心思想是*自注意力机制（self-attention）*——能注意输入序列的不同位置以计算该序列的表示的能力。Transformer 创建了多层自注意力层（self-attetion layers）组成的堆栈，下文的*按比缩放的点积注意力（Scaled dot product attention）*和*多头注意力（Multi-head attention）*部分对此进行了说明。\n",
    "\n",
    "一个 transformer 模型用自注意力层而非 [RNNs](text_classification_rnn.ipynb) 或 [CNNs](../images/intro_to_cnns.ipynb) 来处理变长的输入。这种通用架构有一系列的优势：\n",
    "\n",
    "* 它不对数据间的时间/空间关系做任何假设。这是处理一组对象（objects）的理想选择（例如，[星际争霸单位（StarCraft units）](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)）。\n",
    "* 层输出可以并行计算，而非像 RNN 这样的序列计算。\n",
    "* 远距离项可以影响彼此的输出，而无需经过许多 RNN 步骤或卷积层（例如，参见[场景记忆 Transformer（Scene Memory Transformer）](https://arxiv.org/pdf/1903.03878.pdf)）\n",
    "* 它能学习长距离的依赖。在许多序列任务中，这是一项挑战。\n",
    "\n",
    "该架构的缺点是：\n",
    "\n",
    "* 对于时间序列，一个单位时间的输出是从*整个历史记录*计算的，而非仅从输入和当前的隐含状态计算得到。这*可能*效率较低。   \n",
    "* 如果输入*确实*有时间/空间的关系，像文本，则必须加入一些位置编码，否则模型将有效地看到一堆单词。\n",
    "\n",
    "在此 notebook 中训练完模型后，您将能输入葡萄牙语句子，得到其英文翻译。\n",
    "\n",
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjJJyJTZYebt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    !pip install tf-nightly \n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## 设置输入流水线（input pipeline）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "使用 [TFDS](https://tensorflow.google.cn/datasets) 来导入 [葡萄牙语-英语翻译数据集](https://github.com/neulab/word-embeddings-for-nmt)，该数据集来自于 [TED 演讲开放翻译项目](https://www.ted.com/participate/translate).\n",
    "\n",
    "该数据集包含来约 50000 条训练样本，1100 条验证样本，以及 2000 条测试样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q9t4FmN96eN"
   },
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCEKotqosGfq"
   },
   "source": [
    "从训练数据集创建自定义子词分词器（subwords tokenizer）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVBg5Q8tBk5z"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DYWukNFkGQN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "如果单词不在词典中，则分词器（tokenizer）通过将单词分解为子词来对字符串进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf2ntBxjkqK6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "将开始和结束标记（token）添加到输入和目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "          lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "          lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note：为了使本示例较小且相对较快，删除长度大于40个标记的样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "`.map()` 内部的操作以图模式（graph mode）运行，`.map()` 接收一个不具有 numpy 属性的图张量（graph tensor）。该`分词器（tokenizer）`需要将一个字符串或 Unicode 符号，编码成整数。因此，您需要在 `tf.py_function` 内部运行编码过程，`tf.py_function` 接收一个 eager 张量，该 eager 张量有一个包含字符串值的 numpy 属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "\n",
    "# 将数据集缓存到内存中以加快读取速度。\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,padded_shapes=([-1], [-1]))\n",
    "\n",
    "\n",
    "# 流水线技术 重叠训练的预处理和模型训练步骤。当加速器正在执行训练步骤 N 时，CPU 开始准备步骤 N + 1 的数据。这样做可以将步骤时间减少到模型训练与抽取转换数据二者所需的最大时间（而不是二者时间总和）。\n",
    "# 没有流水线技术，CPU 和 GPU/TPU 大部分时间将处于闲置状态:\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE,padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fXvfYVfQr2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=207712, shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: id=207713, shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## 位置编码（Positional encoding）\n",
    "\n",
    "因为该模型并不包括任何的循环（recurrence）或卷积，所以模型添加了位置编码，为模型提供一些关于单词在句子中相对位置的信息。\n",
    "\n",
    "位置编码向量被加到嵌入（embedding）向量中。嵌入表示一个 d 维空间的标记，在 d 维空间中有着相似含义的标记会离彼此更近。但是，嵌入并没有对在一句话中的词的相对位置进行编码。因此，当加上位置编码后，词将基于*它们含义的相似度以及它们在句子中的位置*，在 d 维空间中离彼此更近。\n",
    "\n",
    "参看 [位置编码](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) 的 notebook 了解更多信息。计算位置编码的公式如下：\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绝对位置：例如每个sequence  , 位置都是从0，1..n开始 \n",
    "- 相对位置：位置的表示是由字与字之间的差表示的。相对位置表达Relative Position Representations (RPR)是Shaw et al., 2018，这个论文指出，同一个sequence中使用相对位置更好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../data/img/position encoding.png\" width=\"900\" alt=\"scaled_dot_product_attention\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kLCla68EloE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../data/img/postion question.png\" width=\"800\" alt=\"scaled_dot_product_attention\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## 遮挡（Masking）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "遮挡一批序列中所有的填充标记（pad tokens）。这确保了模型不会将填充作为输入。该 mask 表明填充值 `0` 出现的位置：在这些位置 mask 输出 `1`，否则输出 `0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7BYeBCNvi7n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207727, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "前瞻遮挡（look-ahead mask）用于遮挡一个序列中的后续标记（future tokens）。换句话说，该 mask 表明了不应该使用的条目。\n",
    "\n",
    "这意味着要预测第三个词，将仅使用第一个和第二个词。与此类似，预测第四个词，仅使用第一个，第二个和第三个词，依此类推。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"\n",
    "    tf.linalg.band_part(\n",
    "        input,\n",
    "        num_lower,\n",
    "        num_upper,\n",
    "        name=None\n",
    "    )\n",
    "    input:输入的张量.\n",
    "    num_lower:下三角矩阵保留的副对角线数量，从主对角线开始计算，相当于下三角的带宽。取值为负数时，则全部保留。\n",
    "    num_upper:上三角矩阵保留的副对角线数量，从主对角线开始计算，相当于上三角的带宽。取值为负数时，则全部保留。\n",
    "    \"\"\"\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxKGuXxaBeeE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207742, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## 按比缩放的点积注意力（Scaled dot product attention）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "Transformer 使用的注意力函数有三个输入：Q（请求（query））、K（主键（key））、V（数值（value））。用于计算注意力权重的等式为：\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "点积注意力被缩小了深度的平方根倍。这样做是因为对于较大的深度值，点积的大小会增大，从而推动 softmax 函数往仅有很小的梯度的方向靠拢，导致了一种很硬的（hard）softmax。\n",
    "\n",
    "例如，假设 `Q` 和 `K` 的均值为0，方差为1。它们的矩阵乘积将有均值为0，方差为 `dk`。因此，*`dk` 的平方根*被用于缩放（而非其他数值），因为，`Q` 和 `K` 的矩阵乘积的均值本应该为 0，方差本应该为1，这样会获得一个更平缓的 softmax。\n",
    "\n",
    "遮挡（mask）与 -1e9（接近于负无穷）相乘。这样做是因为遮挡与缩放的 Q 和 K 的矩阵乘积相加，并在 softmax 之前立即应用。目标是将这些单元归零，因为 softmax 的较大负数输入在输出中接近于零。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- query向量：query顾名思义，是负责寻找这个字的于其他字的相关度（通过其它字的key） \n",
    "- key向量：key向量就是用来于query向量作匹配，得到相关度评分的 \n",
    "- value向量：Value vectors 是实际上的字的表示, 一旦我们得到了字的相关度评分，这些表示是用来加权求和的\n",
    "\n",
    "得到每个字的  之后，我们要得到每个字和句子中其他字的相关关系，我们只需要把这个字的query去和其他字的key作匹配，然后得到分数，最后在通过其它字的value的加权求和（权重就是哪个分数）得到这个字的最终输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"计算注意力权重。\n",
    "    q, k, v 必须具有匹配的前置维度。\n",
    "    k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
    "    虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
    "    但是 mask 必须能进行广播转换以便求和。\n",
    "\n",
    "    参数:\n",
    "    q: 请求的形状 == (..., seq_len_q, depth)\n",
    "    k: 主键的形状 == (..., seq_len_k, depth)\n",
    "    v: 数值的形状 == (..., seq_len_v, depth_v)\n",
    "    mask: Float 张量，其形状能转换成\n",
    "          (..., seq_len_q, seq_len_k)。默认为None。\n",
    "\n",
    "    返回值:\n",
    "    输出，注意力权重\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # 缩放 matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # 将 mask 加入到缩放的张量上。\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n",
    "    # 相加等于1。\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax in a numerically stable way.\"\"\"\n",
    "    x = x - np.max(x)\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0320586 , 0.08714432, 0.23688282, 0.64391426, 0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([1,2,3,4,5*-1e9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "当 softmax 在 K 上进行归一化后，它的值决定了分配到 Q 的重要程度。\n",
    "\n",
    "输出表示注意力权重和 V（数值）向量的乘积。这确保了要关注的词保持原样，而无关的词将被清除掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "        q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAzUAf2DPlNt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# 这条 `请求（query）符合第二个`主键（key）`，\n",
    "# 因此返回了第二个`数值（value）`。\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg6k-fGhgXra"
   },
   "outputs": [],
   "source": [
    "# 这条请求符合重复出现的主键（第三第四个），\n",
    "# 因此，对所有的相关数值取了平均。\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transpose(temp_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAq3YOzUgXhb"
   },
   "outputs": [],
   "source": [
    "# 这条请求符合第一和第二条主键，\n",
    "# 因此，对它们的数值去了平均。\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "将所有请求一起*传递*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dlU8Tm-hYrF"
   },
   "outputs": [],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## 多头注意力（Multi-head attention）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "多头注意力由四部分组成：\n",
    "*    线性层并分拆成多头。\n",
    "*    按比缩放的点积注意力。\n",
    "*    多头及联。\n",
    "*    最后一层线性层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。 \n",
    "\n",
    "将上面定义的 `scaled_dot_product_attention` 函数应用于每个头（进行了广播（broadcasted）以提高效率）。注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用`tf.transpose` 和 `tf.reshape`），并放入最后的 `Dense` 层。\n",
    "\n",
    "Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        分拆最后一个维度到 (num_heads, depth).\n",
    "        转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "创建一个 `MultiHeadAttention` 层进行尝试。在序列中的每个位置 `y`，`MultiHeadAttention` 在序列中的所有其他位置运行所有8个注意力头，在每个位置y，返回一个新的同样长度的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu94p-_-2_BX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## 点式前馈网络（Point wise feed forward network）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "点式前馈网络由两层全联接层组成，两层之间有一个 ReLU 激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mytb1lPyOHLB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## 编码与解码（Encoder and decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "Transformer 模型与标准的[具有注意力机制的序列到序列模型（sequence to sequence with attention model）](nmt_with_attention.ipynb)，遵循相同的一般模式。\n",
    "\n",
    "* 输入语句经过 `N` 个编码器层，为序列中的每个词/标记生成一个输出。\n",
    "* 解码器关注编码器的输出以及它自身的输入（自注意力）来预测下一个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### 编码器层（Encoder layer）\n",
    "\n",
    "每个编码器层包括以下子层：\n",
    "\n",
    "1.   多头注意力（有填充遮挡）\n",
    "2.   点式前馈网络（Point wise feed forward networks）。\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。残差连接有助于避免深度网络中的梯度消失问题。\n",
    "\n",
    "每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。Transformer 中有 N 个编码器层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        # (x-mean) / std,\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzZRXdO0mI48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### 解码器层（Decoder layer）\n",
    "\n",
    "每个解码器层包括以下子层：\n",
    "\n",
    "1.   遮挡的多头注意力（前瞻遮挡和填充遮挡）\n",
    "2.   多头注意力（用填充遮挡）。V（数值）和 K（主键）接收*编码器输出*作为输入。Q（请求）接收*遮挡的多头注意力子层的输出*。\n",
    "3.   点式前馈网络\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。\n",
    "\n",
    "Transformer 中共有 N 个解码器层。\n",
    "\n",
    "当 Q 接收到解码器的第一个注意力块的输出，并且 K 接收到编码器的输出时，注意力权重表示根据编码器的输出赋予解码器输入的重要性。换一种说法，解码器通过查看编码器输出和对其自身输出的自注意力，预测下一个词。参看按比缩放的点积注意力部分的演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        # v, k, q, mask\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne2Bqx8k71l0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### 编码器（Encoder）\n",
    "\n",
    "`编码器` 包括：\n",
    "1.   输入嵌入（Input Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个编码器层（encoder layers）\n",
    "\n",
    "输入经过嵌入（embedding）后，该嵌入与位置编码相加。该加法结果的输出是编码器层的输入。编码器的输出是解码器的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 将嵌入和位置编码相加。\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # 为什么要乘以embedding size的开方？\n",
    "        # 猜测是因为embedding matrix的初始化方式是xavier init，这种方式的方差是1/embedding size，\n",
    "        # 因此乘以embedding size的开方使得embedding matrix的方差是1，在这个scale下可能更有利于embedding matrix的收敛。\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QG9nueFQKXx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### 解码器（Decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    "`解码器`包括：\n",
    "1.   输出嵌入（Output Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个解码器层（decoder layers）\n",
    "\n",
    "目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            # v, k, q\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1jXoAMRZyvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## 创建 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer 包括编码器，解码器和最后的线性层。解码器的输出是线性层的输入，返回线性层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJ4fbQcIkHW1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## 配置超参数（hyperparameters）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "为了让本示例小且相对较快，已经减小了*num_layers、 d_model 和  dff* 的值。 \n",
    "\n",
    "Transformer 的基础模型使用的数值为：*num_layers=6*，*d_model = 512*，*dff = 2048*。关于所有其他版本的 Transformer，请查阅[论文](https://arxiv.org/abs/1706.03762)。\n",
    "\n",
    "Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## 优化器（Optimizer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "根据[论文](https://arxiv.org/abs/1706.03762)中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## 损失函数与指标（Loss and metrics）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "由于目标序列是填充（padded）过的，因此在计算损失函数时，应用填充遮挡非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## 训练与检查点（Training and checkpointing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # 编码器填充遮挡\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解码器的第二个注意力模块使用。\n",
    "    # 该填充遮挡用于遮挡编码器的输出。\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解码器的第一个注意力模块使用。\n",
    "    # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=212764, shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=212799, shape=(1, 1, 5, 5), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=212772, shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_masks(np.array([[1,2,3,0,0]]),np.array([[4,5,6,0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "创建检查点的路径和检查点管理器（manager）。这将用于在每 `n` 个周期（epochs）保存检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"data/checkpoints/transformer/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "目标（target）被分成了 tar_inp 和 tar_real。tar_inp 作为输入传递到解码器。`tar_real` 是位移了 1 的同一个输入：在 `tar_inp` 中的每个位置，`tar_real` 包含了应该被预测到的下一个标记（token）。\n",
    "\n",
    "例如，`sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "Transformer 是一个自回归（auto-regressive）模型：它一次作一个部分的预测，然后使用到目前为止的自身的输出来决定下一步要做什么。\n",
    "\n",
    "在训练过程中，本示例使用了 teacher-forcing 的方法（就像[文本生成教程](./text_generation.ipynb)中一样）。无论模型在当前时间步骤下预测出什么，teacher-forcing 方法都会将真实的输出传递到下一个时间步骤上。\n",
    "\n",
    "当 transformer 预测每个词时，*自注意力（self-attention）*功能使它能够查看输入序列中前面的单词，从而更好地预测下一个单词。\n",
    "\n",
    "为了防止模型在期望的输出上达到峰值，模型使用了前瞻遮挡（look-ahead mask）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地\n",
    "# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变\n",
    "# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定\n",
    "# 更多的通用形状。\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "葡萄牙语作为输入语言，英语为目标语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbvmaKNiznHZ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.3049 Accuracy 0.1366\n",
      "Epoch 1 Batch 50 Loss 2.1597 Accuracy 0.1405\n",
      "Epoch 1 Batch 100 Loss 2.1723 Accuracy 0.1427\n",
      "Epoch 1 Batch 150 Loss 2.1716 Accuracy 0.1442\n",
      "Epoch 1 Batch 200 Loss 2.1620 Accuracy 0.1444\n",
      "Epoch 1 Batch 250 Loss 2.1570 Accuracy 0.1449\n",
      "Epoch 1 Batch 300 Loss 2.1536 Accuracy 0.1459\n",
      "Epoch 1 Batch 350 Loss 2.1500 Accuracy 0.1468\n",
      "Epoch 1 Batch 400 Loss 2.1418 Accuracy 0.1472\n",
      "Epoch 1 Batch 450 Loss 2.1323 Accuracy 0.1478\n",
      "Epoch 1 Batch 500 Loss 2.1234 Accuracy 0.1482\n",
      "Epoch 1 Batch 550 Loss 2.1174 Accuracy 0.1490\n",
      "Epoch 1 Batch 600 Loss 2.1112 Accuracy 0.1497\n",
      "Epoch 1 Batch 650 Loss 2.1057 Accuracy 0.1508\n",
      "Epoch 1 Batch 700 Loss 2.0976 Accuracy 0.1515\n",
      "Epoch 1 Loss 2.0972 Accuracy 0.1515\n",
      "Time taken for 1 epoch: 69.73782730102539 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.8936 Accuracy 0.1687\n",
      "Epoch 2 Batch 50 Loss 1.9290 Accuracy 0.1637\n",
      "Epoch 2 Batch 100 Loss 1.9172 Accuracy 0.1649\n",
      "Epoch 2 Batch 150 Loss 1.9228 Accuracy 0.1668\n",
      "Epoch 2 Batch 200 Loss 1.9271 Accuracy 0.1681\n",
      "Epoch 2 Batch 250 Loss 1.9259 Accuracy 0.1698\n",
      "Epoch 2 Batch 300 Loss 1.9226 Accuracy 0.1713\n",
      "Epoch 2 Batch 350 Loss 1.9153 Accuracy 0.1722\n",
      "Epoch 2 Batch 400 Loss 1.9054 Accuracy 0.1731\n",
      "Epoch 2 Batch 450 Loss 1.8979 Accuracy 0.1743\n",
      "Epoch 2 Batch 500 Loss 1.8920 Accuracy 0.1754\n",
      "Epoch 2 Batch 550 Loss 1.8881 Accuracy 0.1765\n",
      "Epoch 2 Batch 600 Loss 1.8833 Accuracy 0.1774\n",
      "Epoch 2 Batch 650 Loss 1.8758 Accuracy 0.1784\n",
      "Epoch 2 Batch 700 Loss 1.8672 Accuracy 0.1791\n",
      "Epoch 2 Loss 1.8669 Accuracy 0.1791\n",
      "Time taken for 1 epoch: 61.60516142845154 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.5946 Accuracy 0.1846\n",
      "Epoch 3 Batch 50 Loss 1.6959 Accuracy 0.1942\n",
      "Epoch 3 Batch 100 Loss 1.6879 Accuracy 0.1962\n",
      "Epoch 3 Batch 150 Loss 1.6809 Accuracy 0.1965\n",
      "Epoch 3 Batch 200 Loss 1.6864 Accuracy 0.1978\n",
      "Epoch 3 Batch 250 Loss 1.6804 Accuracy 0.1986\n",
      "Epoch 3 Batch 300 Loss 1.6770 Accuracy 0.2001\n",
      "Epoch 3 Batch 350 Loss 1.6683 Accuracy 0.2005\n",
      "Epoch 3 Batch 400 Loss 1.6636 Accuracy 0.2012\n",
      "Epoch 3 Batch 450 Loss 1.6599 Accuracy 0.2023\n",
      "Epoch 3 Batch 500 Loss 1.6582 Accuracy 0.2031\n",
      "Epoch 3 Batch 550 Loss 1.6521 Accuracy 0.2037\n",
      "Epoch 3 Batch 600 Loss 1.6508 Accuracy 0.2046\n",
      "Epoch 3 Batch 650 Loss 1.6488 Accuracy 0.2053\n",
      "Epoch 3 Batch 700 Loss 1.6458 Accuracy 0.2058\n",
      "Epoch 3 Loss 1.6460 Accuracy 0.2058\n",
      "Time taken for 1 epoch: 61.85613822937012 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3377 Accuracy 0.2196\n",
      "Epoch 4 Batch 50 Loss 1.4974 Accuracy 0.2218\n",
      "Epoch 4 Batch 100 Loss 1.4852 Accuracy 0.2208\n",
      "Epoch 4 Batch 150 Loss 1.4843 Accuracy 0.2220\n",
      "Epoch 4 Batch 200 Loss 1.4879 Accuracy 0.2222\n",
      "Epoch 4 Batch 250 Loss 1.4914 Accuracy 0.2227\n",
      "Epoch 4 Batch 300 Loss 1.4882 Accuracy 0.2234\n",
      "Epoch 4 Batch 350 Loss 1.4817 Accuracy 0.2238\n",
      "Epoch 4 Batch 400 Loss 1.4785 Accuracy 0.2243\n",
      "Epoch 4 Batch 450 Loss 1.4740 Accuracy 0.2246\n",
      "Epoch 4 Batch 500 Loss 1.4754 Accuracy 0.2249\n",
      "Epoch 4 Batch 550 Loss 1.4722 Accuracy 0.2253\n",
      "Epoch 4 Batch 600 Loss 1.4686 Accuracy 0.2254\n",
      "Epoch 4 Batch 650 Loss 1.4658 Accuracy 0.2259\n",
      "Epoch 4 Batch 700 Loss 1.4624 Accuracy 0.2265\n",
      "Epoch 4 Loss 1.4622 Accuracy 0.2266\n",
      "Time taken for 1 epoch: 61.183122634887695 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.1163 Accuracy 0.2196\n",
      "Epoch 5 Batch 50 Loss 1.3081 Accuracy 0.2402\n",
      "Epoch 5 Batch 100 Loss 1.3056 Accuracy 0.2414\n",
      "Epoch 5 Batch 150 Loss 1.3021 Accuracy 0.2418\n",
      "Epoch 5 Batch 200 Loss 1.3045 Accuracy 0.2433\n",
      "Epoch 5 Batch 250 Loss 1.2980 Accuracy 0.2433\n",
      "Epoch 5 Batch 300 Loss 1.2933 Accuracy 0.2434\n",
      "Epoch 5 Batch 350 Loss 1.2905 Accuracy 0.2439\n",
      "Epoch 5 Batch 400 Loss 1.2839 Accuracy 0.2444\n",
      "Epoch 5 Batch 450 Loss 1.2806 Accuracy 0.2451\n",
      "Epoch 5 Batch 500 Loss 1.2816 Accuracy 0.2457\n",
      "Epoch 5 Batch 550 Loss 1.2784 Accuracy 0.2463\n",
      "Epoch 5 Batch 600 Loss 1.2776 Accuracy 0.2472\n",
      "Epoch 5 Batch 650 Loss 1.2764 Accuracy 0.2478\n",
      "Epoch 5 Batch 700 Loss 1.2758 Accuracy 0.2481\n",
      "Saving checkpoint for epoch 5 at data/checkpoints/transformer/train/ckpt-1\n",
      "Epoch 5 Loss 1.2761 Accuracy 0.2482\n",
      "Time taken for 1 epoch: 61.93812704086304 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.1067 Accuracy 0.2675\n",
      "Epoch 6 Batch 50 Loss 1.1071 Accuracy 0.2655\n",
      "Epoch 6 Batch 100 Loss 1.1178 Accuracy 0.2656\n",
      "Epoch 6 Batch 150 Loss 1.1137 Accuracy 0.2647\n",
      "Epoch 6 Batch 200 Loss 1.1130 Accuracy 0.2640\n",
      "Epoch 6 Batch 250 Loss 1.1156 Accuracy 0.2640\n",
      "Epoch 6 Batch 300 Loss 1.1126 Accuracy 0.2639\n",
      "Epoch 6 Batch 350 Loss 1.1161 Accuracy 0.2644\n",
      "Epoch 6 Batch 400 Loss 1.1180 Accuracy 0.2649\n",
      "Epoch 6 Batch 450 Loss 1.1171 Accuracy 0.2649\n",
      "Epoch 6 Batch 500 Loss 1.1179 Accuracy 0.2652\n",
      "Epoch 6 Batch 550 Loss 1.1173 Accuracy 0.2656\n",
      "Epoch 6 Batch 600 Loss 1.1192 Accuracy 0.2661\n",
      "Epoch 6 Batch 650 Loss 1.1209 Accuracy 0.2665\n",
      "Epoch 6 Batch 700 Loss 1.1204 Accuracy 0.2667\n",
      "Epoch 6 Loss 1.1207 Accuracy 0.2667\n",
      "Time taken for 1 epoch: 61.51435089111328 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.0567 Accuracy 0.2774\n",
      "Epoch 7 Batch 50 Loss 0.9951 Accuracy 0.2816\n",
      "Epoch 7 Batch 100 Loss 0.9911 Accuracy 0.2800\n",
      "Epoch 7 Batch 150 Loss 0.9948 Accuracy 0.2785\n",
      "Epoch 7 Batch 200 Loss 0.9948 Accuracy 0.2782\n",
      "Epoch 7 Batch 250 Loss 1.0036 Accuracy 0.2791\n",
      "Epoch 7 Batch 300 Loss 1.0060 Accuracy 0.2799\n",
      "Epoch 7 Batch 350 Loss 1.0079 Accuracy 0.2797\n",
      "Epoch 7 Batch 400 Loss 1.0067 Accuracy 0.2797\n",
      "Epoch 7 Batch 450 Loss 1.0061 Accuracy 0.2798\n",
      "Epoch 7 Batch 500 Loss 1.0067 Accuracy 0.2796\n",
      "Epoch 7 Batch 550 Loss 1.0081 Accuracy 0.2798\n",
      "Epoch 7 Batch 600 Loss 1.0110 Accuracy 0.2804\n",
      "Epoch 7 Batch 650 Loss 1.0118 Accuracy 0.2805\n",
      "Epoch 7 Batch 700 Loss 1.0127 Accuracy 0.2807\n",
      "Epoch 7 Loss 1.0127 Accuracy 0.2808\n",
      "Time taken for 1 epoch: 61.38774585723877 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.7567 Accuracy 0.2424\n",
      "Epoch 8 Batch 50 Loss 0.8913 Accuracy 0.2870\n",
      "Epoch 8 Batch 100 Loss 0.8943 Accuracy 0.2889\n",
      "Epoch 8 Batch 150 Loss 0.8991 Accuracy 0.2898\n",
      "Epoch 8 Batch 200 Loss 0.9008 Accuracy 0.2898\n",
      "Epoch 8 Batch 250 Loss 0.9100 Accuracy 0.2901\n",
      "Epoch 8 Batch 300 Loss 0.9136 Accuracy 0.2903\n",
      "Epoch 8 Batch 350 Loss 0.9165 Accuracy 0.2907\n",
      "Epoch 8 Batch 400 Loss 0.9179 Accuracy 0.2912\n",
      "Epoch 8 Batch 450 Loss 0.9178 Accuracy 0.2905\n",
      "Epoch 8 Batch 500 Loss 0.9195 Accuracy 0.2906\n",
      "Epoch 8 Batch 550 Loss 0.9215 Accuracy 0.2903\n",
      "Epoch 8 Batch 600 Loss 0.9240 Accuracy 0.2905\n",
      "Epoch 8 Batch 650 Loss 0.9257 Accuracy 0.2906\n",
      "Epoch 8 Batch 700 Loss 0.9268 Accuracy 0.2905\n",
      "Epoch 8 Loss 0.9267 Accuracy 0.2905\n",
      "Time taken for 1 epoch: 61.14361643791199 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8942 Accuracy 0.3183\n",
      "Epoch 9 Batch 50 Loss 0.8349 Accuracy 0.3016\n",
      "Epoch 9 Batch 100 Loss 0.8303 Accuracy 0.3018\n",
      "Epoch 9 Batch 150 Loss 0.8401 Accuracy 0.3022\n",
      "Epoch 9 Batch 200 Loss 0.8401 Accuracy 0.3018\n",
      "Epoch 9 Batch 250 Loss 0.8398 Accuracy 0.3006\n",
      "Epoch 9 Batch 300 Loss 0.8429 Accuracy 0.3006\n",
      "Epoch 9 Batch 350 Loss 0.8430 Accuracy 0.3002\n",
      "Epoch 9 Batch 400 Loss 0.8428 Accuracy 0.2994\n",
      "Epoch 9 Batch 450 Loss 0.8456 Accuracy 0.2995\n",
      "Epoch 9 Batch 500 Loss 0.8480 Accuracy 0.2993\n",
      "Epoch 9 Batch 550 Loss 0.8494 Accuracy 0.2990\n",
      "Epoch 9 Batch 600 Loss 0.8533 Accuracy 0.2993\n",
      "Epoch 9 Batch 650 Loss 0.8551 Accuracy 0.2992\n",
      "Epoch 9 Batch 700 Loss 0.8591 Accuracy 0.2994\n",
      "Epoch 9 Loss 0.8592 Accuracy 0.2995\n",
      "Time taken for 1 epoch: 60.81917333602905 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.6424 Accuracy 0.2660\n",
      "Epoch 10 Batch 50 Loss 0.7666 Accuracy 0.3076\n",
      "Epoch 10 Batch 100 Loss 0.7695 Accuracy 0.3111\n",
      "Epoch 10 Batch 150 Loss 0.7834 Accuracy 0.3119\n",
      "Epoch 10 Batch 200 Loss 0.7871 Accuracy 0.3117\n",
      "Epoch 10 Batch 250 Loss 0.7894 Accuracy 0.3106\n",
      "Epoch 10 Batch 300 Loss 0.7877 Accuracy 0.3102\n",
      "Epoch 10 Batch 350 Loss 0.7894 Accuracy 0.3094\n",
      "Epoch 10 Batch 400 Loss 0.7918 Accuracy 0.3087\n",
      "Epoch 10 Batch 450 Loss 0.7936 Accuracy 0.3083\n",
      "Epoch 10 Batch 500 Loss 0.7943 Accuracy 0.3075\n",
      "Epoch 10 Batch 550 Loss 0.7966 Accuracy 0.3075\n",
      "Epoch 10 Batch 600 Loss 0.7977 Accuracy 0.3072\n",
      "Epoch 10 Batch 650 Loss 0.8023 Accuracy 0.3073\n",
      "Epoch 10 Batch 700 Loss 0.8039 Accuracy 0.3069\n",
      "Saving checkpoint for epoch 10 at data/checkpoints/transformer/train/ckpt-2\n",
      "Epoch 10 Loss 0.8040 Accuracy 0.3069\n",
      "Time taken for 1 epoch: 61.3428635597229 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "  \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## 评估（Evaluate）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6APsFrgImLW"
   },
   "source": [
    "以下步骤用于评估：\n",
    "\n",
    "* 用葡萄牙语分词器（`tokenizer_pt`）编码输入语句。此外，添加开始和结束标记，这样输入就与模型训练的内容相同。这是编码器输入。\n",
    "* 解码器输入为 `start token == tokenizer_en.vocab_size`。\n",
    "* 计算填充遮挡和前瞻遮挡。\n",
    "* `解码器`通过查看`编码器输出`和它自身的输出（自注意力）给出预测。\n",
    "* 选择最后一个词并计算它的 argmax。\n",
    "* 将预测的词连接到解码器输入，然后传递给解码器。\n",
    "* 在这种方法中，解码器根据它预测的之前的词预测下一个。\n",
    "\n",
    "Note：这里使用的模型具有较小的能力以保持相对较快，因此预测可能不太正确。要复现论文中的结果，请使用全部数据集，并通过修改上述超参数来使用基础 transformer 模型或者 transformer XL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    # 输入语句是葡萄牙语，增加开始和结束标记\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # 因为目标是英语，输入 transformer 的第一个词应该是\n",
    "    # 英语的开始标记。\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # 从 seq_len 维度选择最后一个词\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 如果 predicted_id 等于结束标记，就返回结果\n",
    "        if predicted_id == tokenizer_en.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # 画出注意力权重\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsxrAlvFG8SZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to solve the united states that we have to solve a problem .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EH5y_aqI4t1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors have heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-hVCTSUMlkb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i 'll take a lot of sharing with some stories of some magic things that happened .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MxkSZvz0jX"
   },
   "source": [
    "您可以为 `plot` 参数传递不同的层和解码器的注意力模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-kFyiOLH0xg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book i did .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqQ1fIsLwkGE"
   },
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，您已经学习了位置编码，多头注意力，遮挡的重要性以及如何创建一个 transformer。\n",
    "\n",
    "尝试使用一个不同的数据集来训练 transformer。您可也可以通过修改上述的超参数来创建基础 transformer 或者 transformer XL。您也可以使用这里定义的层来创建 [BERT](https://arxiv.org/abs/1810.04805) 并训练最先进的模型。此外，您可以实现 beam search 得到更好的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "https://mp.weixin.qq.com/s/lwAPIdIt98O7EgfMzi4G4Q"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
